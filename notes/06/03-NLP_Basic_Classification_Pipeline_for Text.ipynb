{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Classification Pipeline (without nested cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd #to work with csv files\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#matplotlib imports are used to plot confusion matrices for the classifiers\n",
    "import matplotlib as mpl \n",
    "import matplotlib.cm as cm \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#import feature extraction methods from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "#pre-processing of text\n",
    "import string\n",
    "import re\n",
    "\n",
    "#import classifiers from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#import different metrics to evaluate the classifiers\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import metrics\n",
    "\n",
    "#import time function from time module to track the training duration\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('COVID19_Dataset-text_labels_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(str_list, lemmatize = True):\n",
    "    clean_list = []\n",
    "    \n",
    "    for text in str_list:\n",
    "        # to drop pound sign from hash tags\n",
    "        text = re.sub(r'#', '', text)\n",
    "        words = word_tokenize(text)\n",
    "        clean_words = []\n",
    "        \n",
    "        for word in words:            \n",
    "            # drop words with fewer than 2 characters; drop any punctuation \"words\"\n",
    "            if (len(word) > 1) and (re.match(r'^\\w+$', word)):\n",
    "\n",
    "                if lemmatize:\n",
    "                    lemmatizer = WordNetLemmatizer()\n",
    "            \n",
    "                clean_words.append(word)\n",
    "        clean_text = ' '.join(clean_words)\n",
    "        clean_list.append(clean_text)\n",
    "    \n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on all tweets\n",
    "tweets['clean_tweet'] = clean_text(tweets['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560,) (560,)\n",
      "(420,) (420,)\n",
      "(140,) (140,)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Step 1: train-test split\n",
    "X = tweets['clean_tweet'] #the column text contains textual data to extract features from\n",
    "y = tweets['Is_Unreliable'] #this is the column we are learning to predict. \n",
    "\n",
    "print(X.shape, y.shape)\n",
    "# split X and y into training and testing sets. By default, it splits 75% training and 25% test\n",
    "#random_state=1 for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 1975) (140, 1975)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize train and test data\n",
    "vect = CountVectorizer(lowercase = True,\n",
    "                        stop_words = 'english',\n",
    "                        ngram_range = (1,1)) #instantiate a vectoriezer\n",
    "X_train_dtm = vect.fit_transform(X_train)#use it to extract features from training data\n",
    "#transform testing data (using training data's features)\n",
    "\n",
    "# During transforming, the default behavior of CountVectorizer is to ignore words that \n",
    "# were not observed during fitting. \n",
    "\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "print(X_train_dtm.shape, X_test_dtm.shape)\n",
    "#i.e., the dimension of our feature vector is 1994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77        69\n",
      "           1       0.78      0.79      0.78        71\n",
      "\n",
      "    accuracy                           0.78       140\n",
      "   macro avg       0.78      0.78      0.78       140\n",
      "weighted avg       0.78      0.78      0.78       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier and predict for test data\n",
    "nb = MultinomialNB() #instantiate a Multinomial Naive Bayes model\n",
    "%time nb.fit(X_train_dtm, y_train)#train the model(timing it with an IPython \"magic command\")\n",
    "#calculate evaluation measures:\n",
    "preds = nb.predict(X_test_dtm)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77        69\n",
      "           1       0.76      0.82      0.79        71\n",
      "\n",
      "    accuracy                           0.78       140\n",
      "   macro avg       0.78      0.78      0.78       140\n",
      "weighted avg       0.78      0.78      0.78       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression #import\n",
    "\n",
    "logreg = LogisticRegression(class_weight=\"balanced\") #instantiate a logistic regression model\n",
    "logreg.fit(X_train_dtm, y_train) #fit the model with training data\n",
    "\n",
    "#calculate evaluation measures:\n",
    "preds = logreg.predict(X_test_dtm) #Make predictions on test data\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77        69\n",
      "           1       0.76      0.82      0.79        71\n",
      "\n",
      "    accuracy                           0.78       140\n",
      "   macro avg       0.78      0.78      0.78       140\n",
      "weighted avg       0.78      0.78      0.78       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "classifier = LinearSVC(class_weight='balanced') #instantiate a logistic regression model\n",
    "classifier.fit(X_train_dtm, y_train) #fit the model with training data\n",
    "\n",
    "#calculate evaluation measures:\n",
    "preds = logreg.predict(X_test_dtm) #Make predictions on test data\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
